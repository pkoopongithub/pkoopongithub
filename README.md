- üëã Hi, I‚Äôm @pkoopongithub

- üëÄ I'm interested in psychometrics and the open source development of psychometric tests and much more ...
Since 2012, the D√ºsseldorf student inventory, open source, has served as a learning environment for students of social sciences and trainees in market and social research, application development and data and process analysis.
The D√ºsseldorf student inventory is an open source, valid, precise and independent personality inventory for students in the transition classes (valid, reliable, objective). The D√ºsseldorf student inventory is open to development.
I am happy to provide the raw data, SPSS files, R files and source codes of the programs (Internet, PC, Android- , iOS smartphone available (PHP, MySQL, Xcode, Android Studio, Xamarin, Lazarus).

![screenshot](./profilans.png)

D√ºsseldorfer Sch√ºlerinventar https://mein-duesk.org 

Ich suche einen Partner f√ºr mein D√ºsseldorfer Sch√ºlerinventar https://mein-duesk.org , ein Pers√∂nlichkeitsinventar f√ºr Sch√ºler der √úbergangsklassen der Sekundarstufe I. Ich erstelle auf Basis dieses Inventars f√ºr den Partner Versionen f√ºr PHP, XCode, Android Studio, Xamarin, Delphi und Lazarus. Dazu erstelle ich auch Papierversionen und Handb√ºcher. Der Partner vertreibt die Software √ºber seinen Web-Server, Google Play, den App Store und Amazon, bietet auf seinem Webserver Tests an und beteiligt mich.

---

English
I am seeking a partner for my D√ºsseldorf Student Inventory https://mein-duesk.org , a personality inventory designed for transition students in the lower secondary education level. I will create versions of this inventory for PHP, XCode, Android Studio, Xamarin, Delphi, and Lazarus for the partner. I will also produce paper versions and manuals. The partner will distribute the software through their web server, Google Play, the App Store, and Amazon, offer testing services on their web server, and share the revenue with me.

---

 Fran√ßais
Je recherche un partenaire pour mon Inventaire d‚Äô√âl√®ves de D√ºsseldorf https://mein-duesk.org , un inventaire de personnalit√© destin√© aux √©l√®ves des classes de transition du niveau secondaire inf√©rieur. Je cr√©erai des versions de cet inventaire pour PHP, XCode, Android Studio, Xamarin, Delphi et Lazarus pour le partenaire. Je produirai √©galement des versions papier et des manuels. Le partenaire distribuera le logiciel via son serveur web, Google Play, l'App Store et Amazon, proposera des services de test sur son serveur web et partagera les revenus avec moi.

---

Espa√±ol
Busco un socio para mi Inventario de Estudiantes de D√ºsseldorf https://mein-duesk.org , un inventario de personalidad dise√±ado para estudiantes de las clases de transici√≥n de la educaci√≥n secundaria. Crear√© versiones de este inventario para PHP, XCode, Android Studio, Xamarin, Delphi y Lazarus para el socio. Tambi√©n elaborar√© versiones en papel y manuales. El socio distribuir√° el software a trav√©s de su servidor web, Google Play, la App Store y Amazon, ofrecer√° servicios de pruebas en su servidor web y compartir√° los ingresos conmigo.

---

–†—É—Å—Å–∫–∏–π
–Ø –∏—â—É –ø–∞—Ä—Ç–Ω–µ—Ä–∞ –¥–ª—è –º–æ–µ–≥–æ –î—é—Å—Å–µ–ª—å–¥–æ—Ä—Ñ—Å–∫–æ–≥–æ –ò–Ω–≤–µ–Ω—Ç–∞—Ä—è –°—Ç—É–¥–µ–Ω—Ç–æ–≤ https://mein-duesk.org , –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –æ—Ü–µ–Ω–∫–∏ –ª–∏—á–Ω–æ—Å—Ç–Ω—ã—Ö –∫–∞—á–µ—Å—Ç–≤ –¥–ª—è —É—á–µ–Ω–∏–∫–æ–≤ –ø–µ—Ä–µ—Ö–æ–¥–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤ —Å—Ä–µ–¥–Ω–µ–≥–æ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è. –Ø —Å–æ–∑–¥–∞–º –≤–µ—Ä—Å–∏–∏ —ç—Ç–æ–≥–æ –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è –¥–ª—è PHP, XCode, Android Studio, Xamarin, Delphi –∏ Lazarus –¥–ª—è –ø–∞—Ä—Ç–Ω–µ—Ä–∞. –¢–∞–∫–∂–µ —è –ø–æ–¥–≥–æ—Ç–æ–≤–ª—é –ø–µ—á–∞—Ç–Ω—ã–µ –≤–µ—Ä—Å–∏–∏ –∏ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞. –ü–∞—Ä—Ç–Ω–µ—Ä –±—É–¥–µ—Ç —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è—Ç—å –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ —Å–≤–æ–π –≤–µ–±-—Å–µ—Ä–≤–µ—Ä, Google Play, App Store –∏ Amazon, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ —É—Å–ª—É–≥–∏ –Ω–∞ —Å–≤–æ–µ–º –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–µ –∏ –¥–µ–ª–∏—Ç—å—Å—è –¥–æ—Ö–æ–¥–∞–º–∏ —Å–æ –º–Ω–æ–π.

---

 ‰∏≠Êñá
ÊàëÊ≠£Âú®ÂØªÊâæ‰∏Ä‰∏™Âêà‰Ωú‰ºô‰º¥ÔºåÂÖ±ÂêåÂºÄÂèëÊàëÁöÑÊùúÂ°ûÂ∞îÂ§öÂ§´Â≠¶ÁîüËØÑ‰º∞Â∑•ÂÖ∑ https://mein-duesk.org ÔºåËøôÊòØ‰∏Ä‰∏™‰∏∫‰∏≠Â≠¶ËøáÊ∏°Èò∂ÊÆµÂ≠¶ÁîüËÆæËÆ°ÁöÑ‰∫∫Ê†ºËØÑ‰º∞Â∑•ÂÖ∑„ÄÇÊàëÂ∞Ü‰∏∫Âêà‰Ωú‰ºô‰º¥Âü∫‰∫éÊ≠§ËØÑ‰º∞Â∑•ÂÖ∑ÂºÄÂèëPHP„ÄÅXCode„ÄÅAndroid Studio„ÄÅXamarin„ÄÅDelphiÂíåLazarusÁâàÊú¨ÔºåÂπ∂‰∏îÂà∂‰ΩúÁ∫∏Ë¥®ÁâàÊú¨ÂíåÊâãÂÜå„ÄÇÂêà‰Ωú‰ºô‰º¥Â∞ÜÈÄöËøáÂÖ∂ÁΩëÈ°µÊúçÂä°Âô®„ÄÅGoogle Play„ÄÅApp StoreÂíåAmazonÂàÜÂèëËΩØ‰ª∂ÔºåÊèê‰æõÁΩëÈ°µÊúçÂä°Âô®‰∏äÁöÑÊµãËØïÊúçÂä°ÔºåÂπ∂‰∏éÊàëÂàÜ‰∫´Êî∂ÂÖ•„ÄÇ

When you work on an open source project, you know the intense, personal commitment that contributes to its success. Many users know and appreciate this. However, not everything succeeds with the developers' own strength, especially since in many cases only pure interest in the topic or the use of technologies provide the basis. However, not every user has the skills and the time to support a project. Verbal feedback in the form of error messages is very helpful.

For others, material support may be the only way to get involved in open source.

I would be happy to talk to you about your type of support:

- record further raw data,
- continuously update calibration samples, test statistics, multivariate analyzes, etc.
- improve GUI design,
- Offer a persistent database in compliance with data protection regulations: DB Api and HTTPS Access,
- Include other development environments (Eclipse, Intellij IDE, Lazarus, NetBeans, Scene Builder, Android Studio, Xcode, Visual Studio) on an ongoing basis,
- User training, tutorials, YouTube tutorials,
- technical editing, professional editing.


 My focus is on algorithms and data structures and statistics and data analysis. Since 2012, the D√ºsseldorf Student Inventory, which I developed, has been used as an open-source, valid, reliable, and objective learning platform for learning classical test theory. Due to the Covid-19 crisis, I started digitizing the learning environment in November 2021 (PHP, MySQL, Android Studio, Xcode, Xamarin, Lazarus, R, PSPP) and publishing it on github.



**Algorithmisch Rekursive Sequenzanalyse 2.0**

Ich suche Erben und Nachfolger, die die Algorithmisch-Rekursive Sequenzanalyse weiterentwickeln m√∂chten.

I am looking for heirs and successors to continue the development of Algorithmic Recursive Sequence Analysis.


### Algorithmisch Rekursive Sequenzanalyse 2.0 (ARS 2024)

#### Analyse der Verkaufsgespr√§che und Optimierung der Grammatik

- **Acht Transkripte f√ºr Grammatikinduktion**:
  - [ARS20AchtTranskripte.ipynb](./ARS20AchtTranskripte.ipynb)
  - [ARSEightTranscripts.ipynb](./ARSEightTranscripts.ipynb)
  - [ars20achttranskripte.pdf](./ars20achttranskripte.pdf)
  - [arseighttranscripts.pdf](./arseighttranscripts.pdf)
  
  Acht Verkaufsgespr√§che wurden transkribiert und zur Grammatikinduktion verwendet, um eine Handlungsgrammatik f√ºr Verkaufsgespr√§che zu entwickeln. Die √úbergangswahrscheinlichkeiten der resultierenden Grammatik wurden mit Python optimiert.

- **Intensive Analyse und Implementierung**:
  - [ARS20BeispielEng.pdf](./ARS20BeispielEng.pdf)
  - [ARS20BeispielGer.pdf](./ARS20BeispielGer.pdf)

  Ein einzelnes Transkript wurde anhand einer hypothetischen Grammatik detailliert analysiert. Dabei kamen verschiedene Werkzeuge zum Einsatz: Scheme f√ºr die Grammatikinduktion, Lisp f√ºr den Parser und Transduktor, sowie ein Multi-Agenten-System-Entwurf mit Python.

- **Entwicklung und Optimierung von Chatbots**:
  - [ARS20GramChatBotBSPEng.ipynb](./ARS20GramChatBotBSPEng.ipynb)
  - [ARS20GramChatBotBSPGer.ipynb](./ARS20GramChatBotBSPGer.ipynb)

  Hier wurden Konzepte zur Integration der Grammatik in einen ChatBot vorgestellt.

- **Optimierung der √úbergangswahrscheinlichkeiten**:
  - [ARS20GramOpt.ipynb](./ARS20GramOpt.ipynb)
  - [ARS20GramOpt.pdf](./ARS20GramOpt.pdf)
  - [ARS20GramOptEng.ipynb](./ARS20GramOptEng.ipynb)
  - [ARS2GgramOptEng.pdf](./ARS2GgramOptEng.pdf)

  Diese Dateien enthalten die Optimierung der √úbergangswahrscheinlichkeiten mittels Python.

- **Interpretation und weitere Optimierungen**:
  - [ARS20InterpretationEng.pdf](./ARS20InterpretationEng.pdf)
  - [ARS20InterpretationGer.pdf](./ARS20InterpretationGer.pdf)

  Die √úbergangswahrscheinlichkeiten wurden hier weiter optimiert, wobei R zum Einsatz kam.

- **Grammatik als Bayessches Netz und RNN**:
  - [VKG2RGrammatikAlsBayesNetz.R](./VKG2RGrammatikAlsBayesNetz.R)
  - [VKGGrammatikInduktorRNN.ipynb](./VKGGrammatikInduktorRNN.ipynb)

  Diese Projekte zeigen die Grammatik in Form eines Bayesschen Netzes sowie eine Grammatikinduktion mittels eines rekurrenten neuronalen Netzes (RNN).

- **Konzeptionelle √úberlegungen zu LLM und MAS**:
  - [QualitativeSocialResearchAndLargeLanguageModel.ipynb](./QualitativeSocialResearchAndLargeLanguageModel.ipynb)
  - [QualitativeSozialforschungUndGrossesSprachmodell.ipynb](./QualitativeSozialforschungUndGrossesSprachmodell.ipynb)
  - [QualitativeSozialforschungUndGrossesSprachmodellInduktorTransduktorParserMAS.ipynb](./QualitativeSozialforschungUndGrossesSprachmodellInduktorTransduktorParserMAS.ipynb)
  - [QualitativeSozialforschungUndGrossesSprachmodellInduktorTransduktorParserMAS.pdf](./QualitativeSozialforschungUndGrossesSprachmodellInduktorTransduktorParserMAS.pdf)
  - [VKGKausalinferenzSozialeStrukturenUndProzesse.ipynb](./VKGKausalinferenzSozialeStrukturenUndProzesse.ipynb)
  - [VKGKausalinferenzSozialeStrukturenUndProzesse.pdf](./VKGKausalinferenzSozialeStrukturenUndProzesse.pdf)
  - [VKGMASKausalinferenzSozialeStrukturenUndProzesse.ipynb](./VKGMASKausalinferenzSozialeStrukturenUndProzesse.ipynb)
  - [VKGMASKausalinferenzSozialeStrukturenUndProzesse.pdf](./VKGMASKausalinferenzSozialeStrukturenUndProzesse.pdf)
  - [VKGUeberblickInduktorParserMAS.ipynb](./VKGUeberblickInduktorParserMAS.ipynb)
  - [VKGbayesPython-3.ipynb](./VKGbayesPython-3.ipynb)
  - [VKGmultiagentensystem.ipynb](./VKGmultiagentensystem.ipynb)

  Diese Dateien enthalten √úberlegungen zu gro√üen Sprachmodellen (LLM), Multi-Agenten-Systemen (MAS) und Kausalinferenz im Zusammenhang mit ARS.






### Algorithmisch Rekursive Sequenzanalyse (ARS 1994)

#### Ergebnisse und Implementierungen aus 1994

- **Zusammenfassung der Ergebnisse von ARS 1994**:
  - [PaulKoopARS_Attachments.pdf](./PaulKoopARS_Attachments.pdf)
  - [PaulKoopARS_English_Latex.pdf](./PaulKoopARS_English_Latex.pdf)
  - [PaulKoopARS_chinese.pdf](./PaulKoopARS_chinese.pdf)
  - [PaulKoopARS_english.pdf](./PaulKoopARS_english.pdf)
  - [PaulKoopARS_english_Attachments.pdf](./PaulKoopARS_english_Attachments.pdf)
  - [PaulKoopARS_french.pdf](./PaulKoopARS_french.pdf)
  - [PaulKoopARS_german.pdf](./PaulKoopARS_german.pdf)
  - [PaulKoopARS_german_Attachments.pdf](./PaulKoopARS_german_Attachments.pdf)
  - [PaulKoopARS_german_Latex.pdf](./PaulKoopARS_german_Latex.pdf)
  - [PaulKoopARS_russian.pdf](./PaulKoopARS_russian.pdf)
  - [PaulKoopARS_spain.pdf](./PaulKoopARS_spain.pdf)

  Diese Dokumente fassen die Ergebnisse des ARS-Projekts von 1994 zusammen.

- **Implementierungen in Lisp und Scheme**:
  - [VKG2.lsp](./VKG2.lsp)
  - [vkgEnglishComment.lsp](./vkgEnglishComment.lsp)
  - [vkgGermanComment.lsp](./vkgGermanComment.lsp)
  - [VKG4.scm](./VKG4.scm)
  - [vkgInductorEnglishComment.scm](./vkgInductorEnglishComment.scm)
  - [vkgInductorGermanComment.scm](./vkgInductorGermanComment.scm)

  Der Transduktor wurde in Lisp implementiert, w√§hrend der Induktor in Scheme entwickelt wurde.

- **Parser und zugeh√∂rige Materialien**:
  - [VKGKORPUS.TXT](./VKGKORPUS.TXT)
  - [VKGPARSER.png](./VKGPARSER.png)
  - [LEXIKONVKG.ASC](./LEXIKONVKG.ASC)
  - [PARSERVKG.PAS](./PARSERVKG.PAS)
  - [vkgParser.lsp](./vkgParser.lsp)

  Diese Dateien enthalten den Parser in Pascal und Lisp sowie zugeh√∂rige Materialien.

- **Texte und Forschungsdokumente zu ARS 1994**:
  - [fallstruktur.pdf](./fallstruktur.pdf)
  - [methodologie.pdf](./methodologie.pdf)
  - [oechsle.pdf](./oechsle.pdf)
  - [reku.pdf](./reku.pdf)
  - [GTGentscheidbarkeit.pdf](./GTGentscheidbarkeit.pdf)
  - [KSysteme.pdf](./KSysteme.pdf)

  Diese PDFs bieten zus√§tzliche Informationen zur Methodologie und zu den Ergebnissen von ARS 1994.

- **Tonbandprotokolle von 1994**:
  - [vkg1.mp3](./vkg1.mp3)
  - [vkg2.mp3](./vkg2.mp3)
  - [Aachen_280694_11Uhr.mp3](./Aachen_280694_11Uhr.mp3)

  Diese Audiodateien enthalten das Tonbandprotokoll des Transkripts ‚ÄûText 4‚Äú sowie die acht Tonbandaufnahmen aus dem Jahr 1994.


  ## Algorithmic Recursive Sequence Analysis 2.0 (ARS 2024)

### Sales Dialogue Analysis and Grammar Induction

- [ARS20AchtTranskripte.ipynb](./ARS20AchtTranskripte.ipynb)
- [ARSEightTranscripts.ipynb](./ARSEightTranscripts.ipynb)
- [ars20achttranskripte.pdf](./ars20achttranskripte.pdf)
- [arseighttranscripts.pdf](./arseighttranscripts.pdf)

Eight transcripts of sales dialogues are used for grammar induction to create an action grammar specific to sales conversations. The transition probabilities of the induced grammar are optimized using Python.

- [ARS20BeispielEng.pdf](./ARS20BeispielEng.pdf)
- [ARS20BeispielGer.pdf](./ARS20BeispielGer.pdf)

A single transcript is intensively analyzed based on a prior analysis and the creation of a hypothetical grammar. This involves grammar induction with Scheme, parsing and transduction using Lisp, and the development of a multi-agent system (MAS) with Python.

- [ARS20GramChatBotBSPEng.ipynb](./ARS20GramChatBotBSPEng.ipynb)
- [ARS20GramChatBotBSPGer.ipynb](./ARS20GramChatBotBSPGer.ipynb)

Concept for utilizing the grammar in a ChatBot.

- [ARS20GramOpt.ipynb](./ARS20GramOpt.ipynb)
- [ARS20GramOpt.pdf](./ARS20GramOpt.pdf)
- [ARS20GramOptEng.ipynb](./ARS20GramOptEng.ipynb)
- [ARS2GgramOptEng.pdf](./ARS2GgramOptEng.pdf)

Optimization of grammar transition probabilities (Python).

- [ARS20InterpretationEng.pdf](./ARS20InterpretationEng.pdf)
- [ARS20InterpretationGer.pdf](./ARS20InterpretationGer.pdf)

Optimization of grammar transition probabilities (R).

- [VKG2RGrammatikAlsBayesNetz.R](./VKG2RGrammatikAlsBayesNetz.R)

Representation of the grammar as a Bayesian network.

- [VKGGrammatikInduktorRNN.ipynb](./VKGGrammatikInduktorRNN.ipynb)

Grammar induction using a Recurrent Neural Network (RNN).

### Qualitative Social Research and Large Language Models

- [QualitativeSocialResearchAndLargeLanguageModel.ipynb](./QualitativeSocialResearchAndLargeLanguageModel.ipynb)
- [QualitativeSozialforschungUndGrossesSprachmodell.ipynb](./QualitativeSozialforschungUndGrossesSprachmodell.ipynb)
- [QualitativeSozialforschungUndGrossesSprachmodellInduktorTransduktorParserMAS.ipynb](./QualitativeSozialforschungUndGrossesSprachmodellInduktorTransduktorParserMAS.ipynb)
- [QualitativeSozialforschungUndGrossesSprachmodellInduktorTransduktorParserMAS.pdf](./QualitativeSozialforschungUndGrossesSprachmodellInduktorTransduktorParserMAS.pdf)
- [VKGKausalinferenzSozialeStrukturenUndProzesse.ipynb](./VKGKausalinferenzSozialeStrukturenUndProzesse.ipynb)
- [VKGKausalinferenzSozialeStrukturenUndProzesse.pdf](./VKGKausalinferenzSozialeStrukturenUndProzesse.pdf)
- [VKGMASKausalinferenzSozialeStrukturenUndProzesse.ipynb](./VKGMASKausalinferenzSozialeStrukturenUndProzesse.ipynb)
- [VKGMASKausalinferenzSozialeStrukturenUndProzesse.pdf](./VKGMASKausalinferenzSozialeStrukturenUndProzesse.pdf)
- [VKGUeberblickInduktorParserMAS.ipynb](./VKGUeberblickInduktorParserMAS.ipynb)
- [VKGbayesPython-3.ipynb](./VKGbayesPython-3.ipynb)
- [VKGmultiagentensystem.ipynb](./VKGmultiagentensystem.ipynb)

Conceptual considerations on large language models (LLMs), multi-agent systems (MAS), and causal inference in relation to ARS.

## Algorithmic Recursive Sequence Analysis (ARS 1994)

### Summary of ARS 1994 Results

- [PaulKoopARS_Attachments.pdf](./PaulKoopARS_Attachments.pdf)
- [PaulKoopARS_English_Latex.pdf](./PaulKoopARS_English_Latex.pdf)
- [PaulKoopARS_chinese.pdf](./PaulKoopARS_chinese.pdf)
- [PaulKoopARS_english.pdf](./PaulKoopARS_english.pdf)
- [PaulKoopARS_english_Attachments.pdf](./PaulKoopARS_english_Attachments.pdf)
- [PaulKoopARS_french.pdf](./PaulKoopARS_french.pdf)
- [PaulKoopARS_german.pdf](./PaulKoopARS_german.pdf)
- [PaulKoopARS_german_Attachments.pdf](./PaulKoopARS_german_Attachments.pdf)
- [PaulKoopARS_german_Latex.pdf](./PaulKoopARS_german_Latex.pdf)
- [PaulKoopARS_russian.pdf](./PaulKoopARS_russian.pdf)
- [PaulKoopARS_spain.pdf](./PaulKoopARS_spain.pdf)

Documents summarizing the results of ARS 1994.

### Grammar Tools and Analysis Components

- [VKG2.lsp](./VKG2.lsp)
- [vkgEnglishComment.lsp](./vkgEnglishComment.lsp)
- [vkgGermanComment.lsp](./vkgGermanComment.lsp)

The transducer in Lisp.

- [VKG4.scm](./VKG4.scm)
- [vkgInductorEnglishComment.scm](./vkgInductorEnglishComment.scm)
- [vkgInductorGermanComment.scm](./vkgInductorGermanComment.scm)

The grammar inducer in Scheme.

- [VKGKORPUS.TXT](./VKGKORPUS.TXT)
- [VKGPARSER.png](./VKGPARSER.png)
- [LEXIKONVKG.ASC](./LEXIKONVKG.ASC)
- [PARSERVKG.PAS](./PARSERVKG.PAS)
- [vkgParser.lsp](./vkgParser.lsp)

The parser (Pascal and Lisp).

### Supplementary Texts and Audio Recordings

- [fallstruktur.pdf](./fallstruktur.pdf)
- [methodologie.pdf](./methodologie.pdf)
- [oechsle.pdf](./oechsle.pdf)
- [reku.pdf](./reku.pdf)
- [GTGentscheidbarkeit.pdf](./GTGentscheidbarkeit.pdf)
- [KSysteme.pdf](./KSysteme.pdf)

Texts related to ARS 1994.

- [vkg1.mp3](./vkg1.mp3)
- [vkg2.mp3](./vkg2.mp3)
- [Aachen_280694_11Uhr.mp3](./Aachen_280694_11Uhr.mp3)

Audio recordings of "Text 4" transcript and all eight recordings from 1994.







Repositories:

D√ºsseldorf student inventory:
Open-source, objective, valid and reliable personality inventory for students in transition classes

Algorithmic recursive sequence analysis:
Sequence analytical method for discrete character strings with grammar inducer, grammar parser, grammar transducer

David Deutsch Meditationen:
Reviews of and personal meditations on the two metaphysical publications by David Deutsch

Chess:
Source code didactic program chess self-play mode

Chessteg:
Source code GUI program chess

Beute, Primaten, Genalg:
cellular automata

Pascal:
Console programs (cellular automata. Mini-Max, Alpha-Beta)

Die Algorithmisch rekursive Sequenzanalyse ist das einzige mir bekannte objektiv hermeneutische Verfahren, das vollst√§ndig ohne esoterische Tiefenhermeneutik auskommt, algorithmisch, evolution√§r und memetisch ausgerichtet ist und einen Grammatikinduktor (Scheme) , einen Parser (Pascal) und einen Grammatiktransduktur (Lisp) bietet.¬†

Die Algorithmisch Rekursive Sequenzanalyse ist eine Methode zur Kausalinferenz mit Handlungsgrammatiken und Graphen. Im Gegensatz zu Poststrukturalisten, Postmodernisten, kritischen Posthumanisten und Tiefenhermeneuten nimmt sie Karl Popper, Ulrich Oevermann, Pearl, Bayes, LISP, SCHEME, R und Python sehr ernst.

Algorithmic Recursive Sequence Analysis is a method for causal inference using action grammars and graphs. In contrast to poststructuralists, postmodernists, critical posthumanists and depth hermeneutics, she takes Karl Popper, Ulrich Oevermann, Pearl, Bayes, LISP, SCHEME, R and Python very seriously.


Das D√ºsseldorfer Sch√ºlerinventar ist das einzige mir bekannte quelloffene, valide, reliable und objektive Verfahren, dessen Quellen und Quellcodes √ºberschaubar und nachvollziehbar nachprogrammierbar sind.

Ich freue mich √ºber Erben, die die Verfahren aufgreifen, nachprogrammieren und/oder f√ºr Eigenentwicklungen davon inspirieren lassen.

The algorithmic recursive sequence analysis is the only objective hermeneutic method known to me that does not require any esoteric deep hermeneutics, is algorithmically, evolutionarily and memetically oriented and offers a grammar inductor (Scheme), a parser (Pascal) and a grammar transductor (Lisp).

The D√ºsseldorf student inventory is the only open-source, valid, reliable and objective method that I know of, whose sources and source codes are clear and understandable and can be reprogrammed.

I am happy about heirs who take up the process, reprogram it and/or let it inspire them for their own developments.




**Algorithmisch Rekursive Sequenzanalyse 2.0**

Large Language Models (LLMs), die Interaktionen imitieren und Muster erkennen k√∂nnen, er√∂ffnen interessante neue M√∂glichkeiten f√ºr die soziologische Erforschung von Interaktionssettings. LLMs und das hier besprochene Verfahren k√∂nnen sich tats√§chlich gegenseitig erg√§nzen, anstatt sich auszuschlie√üen. Hier sind einige √úberlegungen dazu, wie das Verfahren erweitert werden k√∂nnte, um von LLMs zu profitieren:

### 1. **Interpretation und Kategorienbildung durch LLMs als Unterst√ºtzung bei der Grammatikinduktion**
   LLMs k√∂nnten tats√§chlich dabei helfen, in gro√üen Transkriptkorpora Kategoriensymbole f√ºr unterschiedliche Satzarten und Gespr√§chsakte (z. B. Fragen, Bitten, Antworten, Einw√§nde) zu identifizieren. Die Modelle sind in der Lage, eine gro√üe Bandbreite an Interaktionen zu imitieren und kontextualisierte Bedeutungen zu verstehen. Durch die Generierung solcher Kategoriensymbole k√∂nnten LLMs als "Vorkategorisierer" fungieren, der die Grundlage f√ºr eine tiefergehende, strukturelle Analyse bildet.

### 2. **Automatisierte und transparente Kategorienbildung**
   Ein Vorteil des LLM-Einsatzes w√§re, dass die Kategorisierungslogik automatisiert und flexibel auf gro√üe Datenmengen anwendbar ist. Die Opazit√§t der internen Regeln der LLMs bleibt zwar bestehen, aber durch spezifisches Fine-Tuning und Vergleich zwischen menschlicher und maschineller Kategorisierung k√∂nnten Forscher eine verl√§ssliche, empirisch fundierte Basis f√ºr Kategorien schaffen, die in eine klar strukturierte Grammatik √ºberf√ºhrt werden kann.

### 3. **Ketten von Kategoriensymbolen f√ºr probabilistische Grammatikinduktion**
   Die von LLMs generierten Ketten von Kategoriensymbolen k√∂nnten dann als Eingabe f√ºr die probabilistische Grammatikinduktion dienen. Diese Grammatikinduktion k√∂nnte die Wahrscheinlichkeit und H√§ufigkeit von Gespr√§chsabl√§ufen modellieren und Aussagen √ºber Muster in verschiedenen Interaktionssettings treffen. Das hei√üt, die Grammatik k√∂nnte ein probabilistisches Modell aufbauen, das empirische und k√ºnstlich erzeugte Gespr√§chsverl√§ufe vergleicht.

### 4. **Vergleich empirischer und k√ºnstlicher Kategorienketten zur √úberpr√ºfung von Modellen**
   Die Kombination von empirisch erfassten Kategorienketten mit k√ºnstlich erzeugten Ketten k√∂nnte als Validierungsmethode f√ºr LLMs dienen. Durch den Abgleich von beobachteten Gespr√§chsmustern in der Realit√§t mit den synthetisch generierten k√∂nnten soziologische Forscher R√ºckschl√ºsse auf die Realit√§tsn√§he und die Grenzen der LLM-Simulationen ziehen.

### 5. **Erforschung und Vergleich verschiedener Interaktionssettings**
   Da LLMs spezifische Gespr√§chskontexte imitieren k√∂nnen, k√∂nnten Forscher verschiedene k√ºnstliche Gespr√§chskontexte (z. B. Verkaufsgespr√§ch, Beratungsgespr√§ch) generieren lassen und diese dann mit empirischen Daten aus √§hnlichen Settings vergleichen. Durch den Einsatz der probabilistischen Grammatikinduktion k√∂nnten Unterschiede oder Gemeinsamkeiten in Interaktionsmustern zwischen den k√ºnstlich generierten und den realen Daten identifiziert und soziologisch interpretiert werden.

### 6. **√úberpr√ºfung und Weiterentwicklung soziologischer Hypothesen**
   Indem sie k√ºnstlich erzeugte Kategorienketten zur Modellierung realer Interaktionen nutzen, k√∂nnten Forscher Hypothesen √ºber Gespr√§chsstrukturen, Machtverh√§ltnisse oder andere Interaktionsdynamiken √ºberpr√ºfen und weiterentwickeln. Sie k√∂nnten beispielsweise untersuchen, ob die H√§ufigkeit bestimmter Muster von Interaktionen in k√ºnstlich erzeugten Kontexten √§hnlich verteilt ist wie in der Realit√§t und wo signifikante Abweichungen bestehen.

### Fazit
Das Verfahren ist durch den Einsatz von LLMs keineswegs √ºberholt, sondern kann durch sie ausgebaut werden. LLMs k√∂nnten in der Vorverarbeitung und in der automatisierten Kategorisierung von Gespr√§chssequenzen hilfreich sein. In der zweiten Phase, in der Grammatikinduktion und Grammatiktransduktion, bleiben die soziologische Analyse und die Interpretation von Kategorienketten jedoch nach wie vor erforderlich, da die Modelle allein die Komplexit√§t soziologischer Hypothesen und Interpretationen nicht erfassen k√∂nnen.



Large Language Models (LLMs), which can imitate interactions and recognize patterns, offer interesting new possibilities for the sociological study of interaction settings. The procedure discussed here and LLMs can actually complement each other rather than replace one another. Here are some considerations on how the procedure could be expanded to benefit from LLMs:

### 1. **Interpretation and Category Formation by LLMs as Support for Grammar Induction**
   LLMs could indeed help identify category symbols for different types of sentences and conversational acts (e.g., questions, requests, responses, objections) in large corpora of transcripts. The models can imitate a wide range of interactions and understand contextualized meanings. By generating such category symbols, LLMs could act as "pre-categorizers," providing the foundation for a more in-depth structural analysis.

### 2. **Automated and Transparent Category Formation**
   One advantage of using LLMs would be the automated and flexible application of categorization logic to large datasets. Although the internal rules of LLMs remain opaque, specific fine-tuning and comparisons between human and machine categorization could enable researchers to create a reliable, empirically based foundation for categories, which can then be translated into a clear structural grammar.

### 3. **Chains of Category Symbols for Probabilistic Grammar Induction**
   The chains of category symbols generated by LLMs could then serve as input for probabilistic grammar induction. This grammar induction could model the probability and frequency of conversational sequences and reveal patterns in various interaction settings. In other words, the grammar could create a probabilistic model that compares empirical and artificially generated conversational sequences.

### 4. **Comparison of Empirical and Artificial Category Chains to Verify Models**
   Combining empirically collected category chains with artificially generated ones could serve as a validation method for LLMs. By comparing observed conversational patterns in reality with synthetically generated ones, sociological researchers could draw conclusions about the realism and limitations of LLM simulations.

### 5. **Exploring and Comparing Different Interaction Settings**
   Since LLMs can imitate specific conversational contexts, researchers could generate various artificial conversational contexts (e.g., sales conversations, advisory sessions) and then compare these with empirical data from similar settings. Using probabilistic grammar induction, differences or similarities in interaction patterns between artificial and real data could be identified and sociologically interpreted.

### 6. **Verification and Further Development of Sociological Hypotheses**
   By using artificially generated category chains to model real interactions, researchers could test and develop hypotheses about conversational structures, power dynamics, or other interaction dynamics. For instance, they could examine whether the frequency of certain interaction patterns in artificially generated contexts is similarly distributed as in reality and where significant deviations exist.

### Conclusion
This procedure is not rendered obsolete by LLMs but can instead be expanded through them. LLMs could assist in the preprocessing and automated categorization of conversational sequences. In the second phase, involving grammar induction and grammar transduction, sociological analysis and interpretation of category chains remain necessary, as the models alone cannot fully capture the complexity of sociological hypotheses and interpretations.



Es w√§re m√∂glich, Methoden wie die objektive Hermeneutik (Oevermann) und die qualitative Inhaltsanalyse (Mayring) durch den Einsatz von Deep Learning und Large Language Models (LLMs) zu ersetzen, um Lesarten, Sinnstrukturen und Kategoriensysteme effizient zu erstellen und Interaktionen zu analysieren. Deep Learning und LLMs k√∂nnen gro√üe Mengen an Text- und Interaktionsdaten verarbeiten und komplexe Muster und Bedeutungsstrukturen autonom erkennen, was eine automatisierte und skalierbare Alternative zur manuellen, interpretativen Analyse der objektiven Hermeneutik darstellt. Durch das Training auf umfangreichen Datens√§tzen sind neuronale Netzwerke in der Lage, Sinnstrukturen und Kategorien zu identifizieren, die sonst m√ºhsam manuell extrahiert werden m√ºssten.

Die Entwicklung einer umfassenden Handlungsgrammatik, die Sinnstrukturen und Kategorien den strukturellen Regeln sozialer Interaktionen zuordnet, bleibt jedoch ein Bereich, der spezialisierte Werkzeuge und formale Programmiersprachen wie Lisp und Scheme erfordert. Die Algorithmisch Rekursive Sequenzanalyse bietet eine regelbasierte Methode zur Induktion von Grammatiken, die die Abfolge und Struktur von Interaktionen formalisiert. Lisp und Scheme eignen sich aufgrund ihrer F√§higkeit, rekursive und regelbasierte Prozesse zu modellieren, besonders gut f√ºr die algorithmische Analyse der Sinnstrukturen. In diesem Sinne bleibt die Handlungsgrammatik ein Aufgabenbereich f√ºr spezialisierte Werkzeuge und Methoden, die tiefgehende strukturelle Einsichten in soziale Sequenzen erm√∂glichen.

It would be possible to replace methods such as objective hermeneutics (Oevermann) and qualitative content analysis (Mayring) with Deep Learning and Large Language Models (LLMs) to efficiently create interpretations, meaning structures, and category systems, as well as to analyze interactions. Deep Learning and LLMs can process large amounts of text and interaction data, autonomously recognizing complex patterns and meaning structures, thus providing an automated and scalable alternative to the manual interpretative analysis of objective hermeneutics. By training on extensive datasets, neural networks can identify meaning structures and categories that would otherwise have to be painstakingly extracted manually.

However, developing a comprehensive action grammar that assigns meaning structures and categories to the structural rules of social interactions remains a field requiring specialized tools and formal programming languages such as Lisp and Scheme. Algorithmic Recursive Sequence Analysis offers a rule-based method for the induction of grammars, formalizing the sequence and structure of interactions. Lisp and Scheme are particularly well-suited for the algorithmic analysis of meaning structures due to their ability to model recursive and rule-based processes. In this sense, action grammar remains a specialized area for tools and methods that enable deeper structural insights into social sequences.






In den vergangenen vier Jahrzehnten hat sich die Forschung und Datenanalyse durch technologische Fortschritte tiefgreifend gewandelt. Die algorithmisch gest√ºtzte Rekonstruktion sozialer Interaktionen erfordert heute Ans√§tze, die gro√üe Datenmengen und die zunehmende Komplexit√§t sozialer Ph√§nomene ber√ºcksichtigen. Die *Algorithmisch Rekursive Sequenzanalyse (ARS)* ist eine innovative Softwarel√∂sung, die Forschern erm√∂glicht, soziale Interaktionen strukturiert zu analysieren und latente Muster in Kommunikationsabl√§ufen sichtbar zu machen. ARS nutzt Induktion, Parsing und Transduktion, um Handlungsgrammatiken zu generieren, die latente Sinnstrukturen abbilden ‚Äì Strukturen, die in sozialen Interaktionen unbewusst und wiederkehrend reproduziert werden.

Vor 40 Jahren war ein solches Werkzeug aufgrund praktischer Einschr√§nkungen nur eingeschr√§nkt nutzbar. Die verf√ºgbaren Datens√§tze beschr√§nkten sich auf physische Tonband- oder Videoaufnahmen (Protokolle), die zun√§chst in schriftliche Form (Transkripte) √ºbertragen werden mussten. Diese Transkripte wurden dann manuell von Auswertungsteams in einzelne Interakte zerlegt und mit symbolischen Kategorien versehen ‚Äì ein zeitaufw√§ndiger Prozess, der die Analyse und das Erkennen komplexer sozialer Strukturen erschwerte. Erst danach konnte mit der Modellierung der latenten Strukturen durch Handlungsgrammatiken begonnen werden, indem Terminalzeichenketten erstellt, aus diesen durch Induktion die Grammatik abgeleitet und anschlie√üend die Strukturen durch Parsing und Transduktion empirisch validiert wurden.

Heute hingegen kann ARS dank moderner Algorithmen, leistungsf√§higer Computerinfrastruktur und umfangreicher Datens√§tze sein volles Potenzial entfalten. Fortschritte in der Verarbeitung nat√ºrlicher Sprache, etwa durch gro√üe Sprachmodelle, erm√∂glichen eine Automatisierung der Transkription, Interaktanalyse und Kategorisierung. Dadurch lassen sich die latenten Handlungsstrukturen und Sinnmuster, die sozialen Interaktionen zugrunde liegen, gezielt offenlegen. ARS ist somit nicht nur ein Werkzeug f√ºr die qualitative Sozialforschung, sondern er√∂ffnet als interdisziplin√§res Forschungsinstrument neue M√∂glichkeiten des Verst√§ndnisses in den Sozialwissenschaften und dar√ºber hinaus.



Over the past four decades, research and data analysis have been profoundly transformed by technological advancements. Algorithmic reconstruction of social interactions now demands approaches that address large datasets and the increasing complexity of social phenomena. The *Algorithmic Recursive Sequence Analysis (ARS)* is an innovative software solution that enables researchers to systematically analyze social interactions and uncover latent patterns in communication sequences. ARS employs induction, parsing, and transduction to generate action grammars that capture latent semantic structures‚Äîstructures that are unconsciously and recurrently reproduced within social interactions.

Forty years ago, such a tool would have been limited by practical constraints. Available datasets were confined to physical audio or video recordings (protocols), which first had to be transcribed into written form (transcripts). These transcripts were then manually segmented by research teams into individual interaction acts and assigned symbolic categories‚Äîa time-intensive process that made the analysis and identification of complex social structures difficult. Only after this process could the modeling of latent structures through action grammars begin, involving the creation of terminal symbol sequences, the induction of grammar from these sequences, and the validation of structures via parsing and transduction against empirical data.


Empirical social research is currently developing in three directions:
 
With the founding of the German Academy for Sociology, in Germany quantitative social research has regained importance and students have to learn the necessary basics again during their studies.
 
Qualitative social research continues on its way between deep hermeneutics and Oevermannian sequence analysis.
 
Multi-agent systems, neural nets, cellular automata, etc. continue to form the basis for the development of artificial social systems.
 
What is missing is qualitative social research that provides the empirically proven protocol languages for such artificial social systems, which serves to simulate empirically proven models (https://github.com/pkoopongithub). This is not possible with large language models, which hardly go beyond the explanatory value of Markov chains, but only with graph-based models that depict causal inference and rule-based action in an explanatory manner.

Die empirische Sozialforschung entwickelt sich derzeit in drei Richtungen:

Mit der Gr√ºndung der Deutschen Akademie f√ºr Soziologie hat in Deutschland die quantitative Sozialforschung wieder an Bedeutung gewonnen und die Studierenden m√ºssen sich w√§hrend des Studiums die notwendigen Grundlagen neu aneignen.
 
Die qualitative Sozialforschung bewegt sich weiter zwischen Tiefenhermeneutik und Oevermannscher Sequenzanalyse.
 
Multiagentensysteme, neuronale Netze, zellulare Automaten etc. bilden weiterhin die Grundlage f√ºr die Entwicklung k√ºnstlicher sozialer Systeme.
 
Was fehlt, ist eine qualitative Sozialforschung, die die empirisch erprobten Protokollsprachen f√ºr solche k√ºnstlichen Sozialsysteme bereitstellt, die dazu dient, empirisch erprobte Modelle zu simulieren (https://github.com/pkoopongithub). Das geht nicht mit Large Language Modellen, die kaum √ºber den Erkl√§rungswert von Markow-Ketten hinausgehen, sondern nur mit graphenbasierten Modellen, die kausale Inferenz und regelbasiertes Handeln erkl√§rend abbilden.





Es w√§re m√∂glich, Methoden wie die objektive Hermeneutik (Oevermann) und die qualitative Inhaltsanalyse (Mayring) durch den Einsatz von Deep Learning und Large Language Models (LLMs) zu ersetzen, um Lesarten, Sinnstrukturen und Kategoriensysteme effizient zu erstellen und Interaktionen zu analysieren. Deep Learning und LLMs k√∂nnen gro√üe Mengen an Text- und Interaktionsdaten verarbeiten und komplexe Muster und Bedeutungsstrukturen autonom erkennen, was eine automatisierte und skalierbare Alternative zur manuellen, interpretativen Analyse der objektiven Hermeneutik darstellt. Durch das Training auf umfangreichen Datens√§tzen sind neuronale Netzwerke in der Lage, Sinnstrukturen und Kategorien zu identifizieren, die sonst m√ºhsam manuell extrahiert werden m√ºssten.

Die Entwicklung einer umfassenden Handlungsgrammatik, die Sinnstrukturen und Kategorien den strukturellen Regeln sozialer Interaktionen zuordnet, bleibt jedoch ein Bereich, der spezialisierte Werkzeuge und formale Programmiersprachen wie Lisp und Scheme erfordert. Die Algorithmisch Rekursive Sequenzanalyse bietet eine regelbasierte Methode zur Induktion von Grammatiken, die die Abfolge und Struktur von Interaktionen formalisiert. Lisp und Scheme eignen sich aufgrund ihrer F√§higkeit, rekursive und regelbasierte Prozesse zu modellieren, besonders gut f√ºr die algorithmische Analyse der Sinnstrukturen. In diesem Sinne bleibt die Handlungsgrammatik ein Aufgabenbereich f√ºr spezialisierte Werkzeuge und Methoden, die tiefgehende strukturelle Einsichten in soziale Sequenzen erm√∂glichen.



It would be possible to replace methods such as objective hermeneutics (Oevermann) and qualitative content analysis (Mayring) with Deep Learning and Large Language Models (LLMs) to efficiently create interpretations, meaning structures, and category systems, as well as to analyze interactions. Deep Learning and LLMs can process large amounts of text and interaction data, autonomously recognizing complex patterns and meaning structures, thus providing an automated and scalable alternative to the manual interpretative analysis of objective hermeneutics. By training on extensive datasets, neural networks can identify meaning structures and categories that would otherwise have to be painstakingly extracted manually.

However, developing a comprehensive action grammar that assigns meaning structures and categories to the structural rules of social interactions remains a field requiring specialized tools and formal programming languages such as Lisp and Scheme. Algorithmic Recursive Sequence Analysis offers a rule-based method for the induction of grammars, formalizing the sequence and structure of interactions. Lisp and Scheme are particularly well-suited for the algorithmic analysis of meaning structures due to their ability to model recursive and rule-based processes. In this sense, action grammar remains a specialized area for tools and methods that enable deeper structural insights into social sequences.


Wenn das Ziel darin besteht, Verkaufsgespr√§che zu erkl√§ren ‚Äì also die zugrunde liegenden Regeln, Ziele und Strukturen offen darzustellen ‚Äì, dann ist ein generatives Modell wie ein LLM oft unzureichend. Ein LLM kann lediglich √§hnliche Gespr√§che erzeugen oder imitieren, ohne die Absichten oder sozialen Mechanismen dahinter explizit zu machen.

 Wesentliche Punkte des Arguments

1. Nachahmung vs. Erkl√§rung: LLMs sind darauf trainiert, Muster aus gro√üen Textmengen zu lernen und Antworten zu generieren, die oberfl√§chlich betrachtet einem Verkaufsgespr√§ch √§hneln k√∂nnen. Aber sie haben keine explizite Darstellung der Ziele, Strategien oder Regeln, die Verkaufsgespr√§che formen. Somit bleibt die Erkl√§rung der zugrunde liegenden Strukturen unzureichend.
  
2. Erkl√§rungsdefizit: Verkaufsgespr√§che folgen oft bestimmten Regeln und Zielen, wie zum Beispiel dem Aufbau von Vertrauen, der Ermittlung von Kundenbed√ºrfnissen oder der Anwendung spezifischer Verhandlungstechniken. Ein LLM kann zwar solche Techniken reproduzieren, erkl√§rt jedoch nicht, warum und wie diese Strategien funktionieren. Hierf√ºr w√§re ein analytischer Ansatz notwendig, der die Struktur und Dynamik solcher Gespr√§che explizit modelliert.

3. Beitrag von LLMs zu Verst√§ndniszwecken begrenzt: Da LLMs auf Wahrscheinlichkeitsverteilungen und Muster basieren, zeigen sie keine bewusste Zielgerichtetheit und keine kausalen Regeln, die Verkaufsgespr√§che leiten. Wenn das Ziel also darin besteht, die Funktionsweise dieser Gespr√§che zu verstehen und zu lehren, w√§re ein LLM allein unzureichend ‚Äì es braucht erg√§nzende Modelle oder Theorien, die die Handlungslogiken und Ziele explizit beschreiben.

 Erg√§nzende Ans√§tze zur Erkl√§rung von Verkaufsgespr√§chen

- Regelbasierte Modelle: Durch die Verwendung von regelbasierten Systemen oder graphenbasierten Modellen k√∂nnten die Handlungslogiken, Ziele und Entscheidungsstrukturen von Verkaufsgespr√§chen explizit dargestellt werden. Diese Modelle k√∂nnten die spezifischen Verhaltensweisen und Reaktionen in einem Verkaufsgespr√§ch verdeutlichen und die Verbindungen zwischen verschiedenen Gespr√§chszielen und -taktiken erkl√§ren.
  
- Agentenbasierte Modelle: Multiagentensysteme, die auf kausalen und regelbasierten Prinzipien basieren, k√∂nnten die Dynamik und das Ziel eines Verkaufsgespr√§chs explizit abbilden. Solche Systeme k√∂nnen zudem eine gewisse Zielgerichtetheit simulieren, die Verkaufsstrategien realistischer und transparenter macht.

- Dialoggrammatiken: Mit spezifischen Protokollen oder Dialoggrammatiken k√∂nnten die Abl√§ufe und Regeln f√ºr Verkaufsgespr√§che detaillierter dargestellt und somit besser erkl√§rt werden, als es durch ein generatives Modell m√∂glich ist.




Das Argument ist schl√ºssig, da es darauf hinweist, dass die F√§higkeit, Verkaufsgespr√§che zu imitieren, nicht mit der F√§higkeit gleichzusetzen ist, diese Gespr√§che in ihren Regeln und Zielen zu erkl√§ren. Ein LLM mag Verkaufsgespr√§che simulieren k√∂nnen, aber ohne ein explizites Regelwerk und ohne Verst√§ndnis f√ºr die Ziele solcher Gespr√§che liefert es keine ad√§quate Erkl√§rung.


Die Algorithmisch Rekursive Sequenzanalyse ist eine Methode zur Kausalinferenz mit Handlungsgrammatiken und Graphen. Im Gegensatz zu Poststrukturalisten, Postmodernisten, kritischen Posthumanisten, Konstruktivisten und Tiefenhermeneuten nimmt sie Karl Popper, Ulrich Oevermann, Chomsky, Pearl, Bayes, LISP, SCHEME, R und Python sehr ernst.

Algorithmic Recursive Sequence Analysis is a method for causal inference using action grammars and graphs. In contrast to poststructuralists, postmodernists, critical posthumanists, constructivists and depth hermeneutics, she takes Karl Popper, Ulrich Oevermann, Chomsky, Pearl, Bayes, LISP, SCHEME, R and Python very seriously.

If the goal is to explain sales conversations ‚Äì that is, to openly present the underlying rules, goals and structures ‚Äì then a generative model like an LLM is often inadequate. An LLM can only create or imitate similar conversations without making explicit the intentions or social mechanisms behind them.

 Key points of the argument

1. Imitation vs. Explanation: LLMs are trained to learn patterns from large amounts of text and generate responses that, on the surface, can resemble a sales pitch. But they have no explicit representation of the goals, strategies, or rules that shape sales conversations. The explanation of the underlying structures therefore remains inadequate.
  
2. Explanation deficit: Sales conversations often follow certain rules and goals, such as building trust, identifying customer needs or using specific negotiation techniques. While an LLM can reproduce such techniques, it does not explain why and how these strategies work. This would require an analytical approach that explicitly models the structure and dynamics of such conversations.

3. Contribution of LLMs to understanding purposes limited: Because LLMs are based on probability distributions and patterns, they do not demonstrate conscious targeting and causal rules guiding sales conversations. So if the goal is to understand and teach how these conversations work, an LLM alone would be inadequate - it needs complementary models or theories that explicitly describe the logic of action and goals.

 Complementary approaches to explaining sales conversations

- Rule-based models: By using rule-based systems or graph-based models, the action logic, goals and decision structures of sales discussions could be explicitly represented. These models could clarify the specific behaviors and reactions in a sales conversation and explain the connections between different conversation goals and tactics.
  
- Agent-based models: Multi-agent systems based on causal and rule-based principles could explicitly represent the dynamics and goal of a sales conversation. Such systems can also simulate a certain level of targeting that makes sales strategies more realistic and transparent.

- Dialogue grammars: With specific protocols or dialogue grammars, the processes and rules for sales discussions could be presented in more detail and thus better explained than is possible with a generative model.


Projektziele
Erkl√§rung sozialer Interaktionen: Anstatt komplexe soziale Interaktionen und Verkaufsgespr√§che durch Black-Box-Modelle abzubilden, nutzen wir eine regelbasierte Sprache, die nachvollziehbare und interpretierbare Analysen erm√∂glicht.
Einsatz in Multiagentensystemen: Die entwickelte Sprache kann als Protokoll f√ºr Multiagentensysteme dienen und soll in Python implementiert werden. Der Einsatz solcher Protokollsprachen in Multiagentensystemen er√∂ffnet neue M√∂glichkeiten, transparente und erkl√§rbare Interaktionen zwischen Agenten zu erm√∂glichen.
Innovative Kombination von Methodologien: Der Ansatz verbindet Methoden der soziologischen Hermeneutik und Inhaltsanalyse mit einer formalisierten Sprachentwicklung. Hierdurch wird eine modellbasierte Grammatik induziert, die verschiedene Terminal- und Nicht-Terminal-Symbole umfasst, welche soziale Interaktionen als erkl√§rbare Sequenzen abbilden.

Project Goals
Explaining Social Interactions: Instead of modeling complex social interactions and sales dialogues through black-box models, this project uses a rule-based language that enables understandable and interpretable analyses.
Use in Multi-Agent Systems: The developed language can serve as a protocol for multi-agent systems and will be implemented in Python. The use of such protocol languages in multi-agent systems opens up new possibilities for transparent and explainable interactions among agents.
Innovative Methodological Combination: This approach merges sociological hermeneutics and content analysis with formalized language development. A model-based grammar is induced, encompassing various terminal and non-terminal symbols that represent social interactions as explainable sequences.


Generative Pre-Trained Transformers (GPT) und Large Language Models (LLM) gehen kaum √ºber den Erkl√§rungswert von Markow-Ketten hinaus und m√ºssen zudem mit der Wissensbasis empirisch ermittelter Dialoggrammatiken (Algorithmisch rekursive Sequenzanalyse) und agentenorientierter gewichteter Entscheidungstabellen f√ºr eine bessere Ergebnisqualit√§t optimiert werden. Nur so werden Diaogschnittstellen glaubw√ºrdiger als Markow-Generatoren und nur so werden Protokollsprachen f√ºr Agenten empirisch bew√§hrte Dialogstrukturen abbilden.

Generative Pre-Trained Transformers (GPT) and Large Language Models (LLM) hardly go beyond the explanatory value of Markov chains and must also be optimized with the knowledge base of empirically determined dialog grammars (algorithmically recursive sequence analysis) and agent-oriented weighted decision tables for better quality results. Only in this way will dialog interfaces become more credible than Markov generators and only in this way will protocol languages for agents map empirically proven dialog structures.

Les transformateurs g√©n√©ratifs pr√©-entra√Æn√©s (GPT) et les grands mod√®les de langage (LLM) ne d√©passent gu√®re la valeur explicative des cha√Ænes de Markov et doivent √©galement √™tre optimis√©s avec la base de connaissances des grammaires de dialogue d√©termin√©es empiriquement (analyse de s√©quence r√©cursive algorithmique) et la d√©cision pond√©r√©e orient√©e agent. tableaux pour des r√©sultats de meilleure qualit√©. Ce n'est qu'ainsi que les interfaces de dialogue deviendront plus cr√©dibles que les g√©n√©rateurs de Markov et ce n'est qu'ainsi que les langages de protocole pour les agents cartographieront des structures de dialogue √©prouv√©es empiriquement.

Los Transformadores Generativos (GPT) y los Modelos de Lenguaje Largo (LLM) pre-entrenados dif√≠cilmente van m√°s all√° del valor explicativo de las cadenas de Markov y tambi√©n deben optimizarse con la base de conocimientos de las gram√°ticas de di√°logo determinadas emp√≠ricamente (an√°lisis de secuencias recursivas algor√≠tmicas) y decisiones ponderadas orientadas a agentes . tablas para obtener mejores resultados. Solo entonces las interfaces de di√°logo se vuelven m√°s cre√≠bles que los generadores de Markov y solo entonces los lenguajes de protocolo para los agentes mapean estructuras de di√°logo probadas emp√≠ricamente.

È†êË®ìÁ∑¥ÁöÑÁîüÊàêËΩâÊèõÂô®ÔºàGPTÔºâÂíåÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂæàÈõ£Ë∂ÖË∂äÈ¶¨ÁàæÂèØÂ§´ÈèàÁöÑËß£ÈáãÂÉπÂÄºÔºåÈÇÑÂøÖÈ†àÂà©Áî®Á∂ìÈ©óÁ¢∫ÂÆöÁöÑÂ∞çË©±Ë™ûÊ≥ïÔºàÁÆóÊ≥ïÈÅûÊ≠∏Â∫èÂàóÂàÜÊûêÔºâÂíåÈ∫µÂêë‰∏ªÈ´îÁöÑÂä†Ê¨äÊ±∫Á≠ñÁöÑÁü•Ë≠òÂ∫´ÈÄ≤Ë°åÂÑ™Âåñ. Ë°®‰ª•Áç≤ÂæóÊõ¥Â•ΩÁöÑÁµêÊûú„ÄÇ Âè™ÊúâÈÄôÊ®£ÔºåÂ∞çË©±ÁïåÈù¢ÊâçÊúÉËÆäÂæóÊØîÈ¶¨ÁàæÂèØÂ§´ÁîüÊàêÂô®Êõ¥ÂèØ‰ø°Ôºå‰∏¶‰∏îÂè™ÊúâÈÄôÊ®£Ôºå‰ª£ÁêÜÁöÑÂçîË≠∞Ë™ûË®ÄÊâçÊúÉÊò†Â∞ÑÁ∂ìÈÅéÁ∂ìÈ©óÊ∏¨Ë©¶ÁöÑÂ∞çË©±ÁµêÊßã„ÄÇ

–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—ã–µ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª–∏ (GPT) –∏ –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (LLM) –µ–¥–≤–∞ –ª–∏ –≤—ã—Ö–æ–¥—è—Ç –∑–∞ —Ä–∞–º–∫–∏ –æ–±—ä—è—Å–Ω–∏—Ç–µ–ª—å–Ω–æ–π —Ü–µ–Ω–Ω–æ—Å—Ç–∏ —Ü–µ–ø–µ–π –ú–∞—Ä–∫–æ–≤–∞ –∏ —Ç–∞–∫–∂–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã —Å –ø–æ–º–æ—â—å—é –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤—ã—Ö –≥—Ä–∞–º–º–∞—Ç–∏–∫ (–∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∏–π —Ä–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏) –∏ –∞–≥–µ–Ω—Ç–Ω–æ-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–∑–≤–µ—à–µ–Ω–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π. . —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞. –¢–æ–ª—å–∫–æ —Ç–æ–≥–¥–∞ –¥–∏–∞–ª–æ–≥–æ–≤—ã–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –±–æ–ª–µ–µ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω—ã–º–∏, —á–µ–º –º–∞—Ä–∫–æ–≤—Å–∫–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã, –∏ —Ç–æ–ª—å–∫–æ —Ç–æ–≥–¥–∞ —è–∑—ã–∫–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –¥–∏–∞–ª–æ–≥–æ–≤—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã.

Seeking Partner for Promoting Online Personality Inventory
We are looking for a partner to help promote our online personality inventory at https://mein-duesk.org/index.php?navi=8 This role involves creating and managing social media advertising content, including images, audio, and video. You'll need to explain the registration, data collection, profile creation, and interpretation processes to potential users. Compensation will be performance-based, linked to the effectiveness of your advertising. If you have a talent for digital marketing and are interested in collaboration, please reach out!


Partner gesucht f√ºr die Bewerbung unseres Online-Pers√∂nlichkeitsinventars
Wir suchen einen Partner zur Unterst√ºtzung der Bewerbung unseres Online-Pers√∂nlichkeitsinventars unter https://mein-duesk.org/index.php?navi=8 Diese Rolle beinhaltet die Erstellung und Verwaltung von Social-Media-Werbeinhalten, einschlie√ülich Bilder, Audio und Video. Sie m√ºssen den Anmeldeprozess, die Datenerfassung, die Profilerstellung und -interpretation potenziellen Nutzern erkl√§ren. Die Verg√ºtung erfolgt leistungsbasiert, abh√§ngig vom Erfolg Ihrer Werbung. Wenn Sie ein Talent f√ºr digitales Marketing haben und an einer Zusammenarbeit interessiert sind, melden Sie sich bei uns!





